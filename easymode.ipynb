{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EnsNet Ensemble Learning with Majority Voting on TPU\n----------\n\n## This notebook contains a third party TensorFlow implementation of EnsNet\nA novel CNN architecture, it is one of the state-of-art for MNIST, it can also be tested with Fashion MNIST and CIFAR-10.\n\n[Ensemble Learning in CNN Augmented with Fully Connected Subnetworks](https://arxiv.org/pdf/2003.08562v3.pdf).\n\nEnsNet is designed to enhance image recognition performance by leveraging a base CNN combined with multiple FCSNs, improving accuracy through ensemble learning techniques to then use a majority voting count.\n\n[paperswithcode/image-classification-on-mnist](https://paperswithcode.com/sota/image-classification-on-mnist)","metadata":{}},{"cell_type":"markdown","source":"### Let's make sure we install the dependencies","metadata":{}},{"cell_type":"code","source":"!pip install cloud-tpu-client\n!pip install dropconnect-tensorflow\n!pip install tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2024-03-05T11:41:37.524054Z","iopub.execute_input":"2024-03-05T11:41:37.524548Z","iopub.status.idle":"2024-03-05T11:41:53.238212Z","shell.execute_reply.started":"2024-03-05T11:41:37.524519Z","shell.execute_reply":"2024-03-05T11:41:53.237159Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cloud-tpu-client in /usr/local/lib/python3.10/site-packages (0.10)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client) (4.1.3)\nRequirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/site-packages (from cloud-tpu-client) (1.8.0)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\nRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.2.0)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.22.0)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.1)\nRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (2.28.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (0.3.0)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (4.9)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client) (0.5.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.62.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.31.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (5.3.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client) (3.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.2.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting dropconnect-tensorflow\n  Downloading dropconnect-tensorflow-0.1.1.tar.gz (4.2 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.10/site-packages (from dropconnect-tensorflow) (2.15.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.26.4)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (4.9.0)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (2.15.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (2.15.2)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (2.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (0.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.6.3)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.16.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (16.0.6)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (23.2)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (23.5.26)\nCollecting keras<2.16,>=2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (65.5.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (3.3.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.4.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.62.0)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (0.5.4)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (0.36.0)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (0.2.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (3.20.3)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (3.10.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.2->dropconnect-tensorflow) (1.14.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.2->dropconnect-tensorflow) (0.42.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (0.7.2)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (3.5.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (3.0.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (1.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (2.28.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (5.3.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (1.3.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (2.2.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (3.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (2.1.5)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2->dropconnect-tensorflow) (3.2.2)\nBuilding wheels for collected packages: dropconnect-tensorflow\n  Building wheel for dropconnect-tensorflow (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dropconnect-tensorflow: filename=dropconnect_tensorflow-0.1.1-py3-none-any.whl size=4640 sha256=4813c40afd6bc49f1327568af742d1f9ca1e55a418414e6ffd4bad56d41c2117\n  Stored in directory: /root/.cache/pip/wheels/7e/4a/e5/266cd645dbc3573352598ba045a07b58db04fc73b8cfab99ae\nSuccessfully built dropconnect-tensorflow\nInstalling collected packages: keras, dropconnect-tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dropconnect-tensorflow-0.1.1 keras-2.15.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting tensorflow-addons\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting typeguard<3.0.0,>=2.7\n  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow-addons) (23.2)\nInstalling collected packages: typeguard, tensorflow-addons\nSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, Lambda, MaxPooling2D, Reshape\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom dropconnect_tensorflow import DropConnectDense\nimport tensorflow.keras.backend as K\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Leveraging TPUs for Enhanced Performance in Deep Learning\n\n### Unlike GPUs, TPUs are designed specifically for deep learning. \n- They excel in handling high volumes of matrix and tensor calculations, which are prevalent in deep learning algorithms. \n- This specialization allows for smoother model training and inference by reducing computational bottlenecks.\n## Setting Up the TPU Environment\n- TPU Cluster Resolver: Initialize the TPU system by specifying the TPU's address. TensorFlow provides a simple interface to connect to the TPU cluster.\n- Initializing TPU System: Once connected, we initialize the TPU system, making it ready to execute operations.\n- Distributing with TPUStrategy: TensorFlow's TPUStrategy allows us to define how our model should be distributed and executed across the TPU cores. This strategy handles the distribution of computations and data, optimizing for parallel execution.\n","metadata":{}},{"cell_type":"code","source":"def setup_distribution_strategy():\n    \"\"\"\n    Sets up the TensorFlow distribution strategy based on available hardware, prioritizing TPUs if available.\n\n    Returns:\n    - strategy: The resolved TensorFlow distribution strategy.\n    \"\"\"\n    # Suppress warnings to clean up output\n    warnings.filterwarnings('ignore')\n\n    # Automatically tune the dataset performance\n    AUTO = tf.data.experimental.AUTOTUNE\n\n    try:\n        # Attempt to detect and initialize a TPU\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        # If TPU is found, initialize the TPU system and setup TPU strategy\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        # If TPU is not found, fall back to default strategy (could be CPUs, GPUs)\n        strategy = tf.distribute.get_strategy()\n\n    return strategy, AUTO","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-Processing Data\n\n## Loading Data\n\nWe start loading the MNIST dataset, normalizating inputs by 255 and reshaping it, as well as specifying the number of classes.\n\n## We will create Pre-Processing Functions ourselves. \n\n### But... isn't easier with Keras library \"ImageDataGenerator\"?\n\nYes, but to avoid bottleneck it is neccesary to use tf.data API, which provides more flexibility and efficiency for data loading and preprocessing!\n\nTo fully leverage the power of TPU, we will have to <b>parallelized</b> our data\n\nWe will have to create some manual data augmentation functions, they will include\n\n- <b>Rotation</b>: This is like spinning a picture around a point in the middle. Imagine pinning a photo to a wall and then twisting it left or right without moving its center.\n- <b>Shear</b>: Think of it as pulling the top edge of an image to one side without moving the bottom edge, making the picture look slanted. It's like stretching or compressing one side of the image more than the other.\n- <b>Zoom</b>: This involves making everything in the image bigger (zooming in) or smaller (zooming out). It's like moving a camera lens closer to or further from a scene to change how much of it you see.\n- <b>Shift</b>: This means moving the whole image up, down, left, or right. Picture sliding a photograph across a table without rotating it; every part of the image moves the same distance in the same direction.","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    num_classes = 10\n    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n    return x_train, y_train, x_test, y_test\n\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # Returns 3x3 transform matrix which transforms indicies\n        \n    # Convert degrees to radians\n    rotation = math.pi * rotation / 180.\n    \n    # Rotation Matrix\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([1],dtype='float32')\n    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n    \n    # Shear Matrix\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n    \n    # Zoom Matrix\n    zoom_matrix = tf.reshape(tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3])\n    \n    # Shift Matrix\n    shift_matrix = tf.reshape(tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3])\n\n    return(rotation_matrix)\n\ndef transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated\n    DIM = image.shape[0]\n    XDIM = DIM%2 #fix for size 331\n    rot = 10. * tf.random.normal([1],dtype='float32')\n    shr = 3. * tf.random.normal([1],dtype='float32') \n    h_zoom = .08 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = .08 + tf.random.normal([1],dtype='float32')/10.\n    random_factor = tf.random.uniform([1], minval=0, maxval=1, dtype='float32')\n\n    # Interpolate within the range for height and width zoom factors\n    h_shift = 8. * tf.random.normal([1],dtype='float32') \n    w_shift = 8. * tf.random.normal([1],dtype='float32') \n  \n    # Get transformation matrix\n    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift) \n\n    # List destination pixel indices\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # Rotate destination pixels onto origin pixels\n    idx2 = tf.keras.backend.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = tf.keras.backend.cast(idx2,dtype='int32')\n    idx2 = tf.keras.backend.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # Find origin pixel values           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,1]),label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_datasets(x_train, y_train, x_test, y_test, batch_size, AUTO=tf.data.experimental.AUTOTUNE, augment=True):\n    \"\"\"\n    Prepares training, validation, and test datasets. Optionally applies data augmentation to the training dataset.\n\n    Parameters:\n    - x_train, y_train: Training data and labels.\n    - x_test, y_test: Test data and labels.\n    - batch_size: The size of the batches to use.\n    - AUTO: TensorFlow data experimental AUTOTUNE setting.\n    - augment: Whether to apply augmentation to the training dataset.\n\n    Returns:\n    - train_dataset_augmented: Training dataset, optionally augmented.\n    - train_dataset: Training dataset without augmentation.\n    - val_dataset: Validation dataset.\n    - test_dataset: Test dataset.\n    \"\"\"\n    # Convert the inputs to TensorFlow datasets\n    train_dataset_base = tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32), y_train.astype(np.float32)))\n    test_dataset_base = tf.data.Dataset.from_tensor_slices((x_test.astype(np.float32), y_test.astype(np.float32)))\n\n    # Apply augmentation if enabled\n    if augment:\n        train_dataset_augmented = train_dataset_base.map(transform, num_parallel_calls=AUTO)\n    else:\n        train_dataset_augmented = train_dataset_base\n\n    train_dataset_augmented = train_dataset_augmented.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO)\n    train_dataset = train_dataset_base.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO)\n\n    val_dataset = test_dataset_base.batch(batch_size).cache().prefetch(AUTO)\n    test_dataset = test_dataset_base.batch(batch_size).prefetch(AUTO)\n\n    return train_dataset_augmented, train_dataset, val_dataset, test_dataset,batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(strategy):\n    with strategy.scope():\n        inputs = Input(shape=(28, 28, 1))\n        x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid')(inputs)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(128, (3, 3), activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(512, (3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(1024, (3, 3), activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(2000, (3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.35)(x)\n\n        cnn_output = Flatten()(x)\n        cnn_output = Dense(512, activation='relu')(cnn_output)\n        cnn_output = BatchNormalization()(cnn_output)\n        cnn_output = Dropout(0.5)(cnn_output)\n        cnn_output = DropConnectDense(512, activation='relu', prob=0.5)(cnn_output)\n        cnn_output = Dense(10, activation='softmax')(cnn_output)\n\n        base_output = x\n        shape = K.int_shape(base_output)\n        num_feature_maps = shape[-1]  # This would be 2000 based on your architecture\n        subnet_feature_maps = num_feature_maps // 10  # This assumes an even split\n        subnet_outputs = []\n\n        for i in range(10):\n            subnet_input = Lambda(lambda z: z[:, :, :, i * subnet_feature_maps:(i + 1) * subnet_feature_maps])(base_output)\n            subnet_input = Reshape((shape[1] * shape[2] * subnet_feature_maps,))(subnet_input)\n            fc = Dense(512, activation='relu')(subnet_input)\n            fc = BatchNormalization()(fc)\n            fc = Dropout(0.5)(fc)\n            fc = DropConnectDense(512, activation='relu', prob=0.5)(fc)\n            subnet_output = Dense(10, activation='softmax')(fc)\n            subnet_outputs.append(subnet_output)\n        subnet_outputs.append(cnn_output)\n        full_model = Model(inputs=inputs, outputs=subnet_outputs)\n        \n    return full_model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_cnn_model(inputs):\n    base_output = build_base_model(inputs)\n    cnn_output = Flatten()(base_output)\n    cnn_output = Dense(512, activation='relu')(cnn_output)\n    cnn_output = BatchNormalization()(cnn_output)\n    cnn_output = Dropout(0.5)(cnn_output)\n    cnn_output = DropConnectDense(512, activation='relu', prob=0.5)(cnn_output)\n    cnn_output = Dense(10, activation='softmax')(cnn_output)\n    return cnn_output\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assemble_full_model(strategy):\n        inputs = Input(shape=(28, 28, 1))\n        '''\n           cnn_output = build_cnn_model(inputs)\n        subnet_outputs = build_subnet_model(inputs)\n        '''\n        x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid')(inputs)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(128, (3, 3), activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(512, (3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(1024, (3, 3), activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.35)(x)\n        x = Conv2D(2000, (3, 3), activation='relu', padding='valid')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.35)(x)\n     \n        subnet_outputs.append(cnn_output)\n        full_model = Model(inputs=inputs, outputs=subnet_outputs)\n        return full_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_adamw_optimizer(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, weight_decay=0.0):\n    \"\"\"\n    Initialize and return the AdamW optimizer.\n\n    Parameters:\n    - learning_rate: float, learning rate for the optimizer.\n    - beta_1: float, the exponential decay rate for the 1st moment estimates.\n    - beta_2: float, the exponential decay rate for the 2nd moment estimates.\n    - epsilon: float, a small constant for numerical stability.\n    - weight_decay: float, weight decay rate to apply to weights.\n\n    Returns:\n    - adamw_optimizer: tf.keras.optimizers.Optimizer, the AdamW optimizer configured with the specified parameters.\n    \"\"\"\n    adamw_optimizer = tfa.optimizers.AdamW(\n        learning_rate=learning_rate,\n        beta_1=beta_1,\n        beta_2=beta_2,\n        epsilon=epsilon,\n        weight_decay=weight_decay\n    )\n    return adamw_optimizer\n    \ndef compile_and_train_model(model, train_dataset, train_dataset_augment, val_dataset, x_train_split, batch_size, epochs):\n    \"\"\"\n    Compile and train the given model, utilizing both augmented and non-augmented training data.\n\n    Parameters:\n    - model: tf.keras.Model, the model to compile and train.\n    - train_dataset: tf.data.Dataset, the non-augmented dataset for training the model.\n    - train_dataset_augment: tf.data.Dataset, the augmented dataset for training the model.\n    - val_dataset: tf.data.Dataset, the dataset for validating the model during training.\n    - x_train_split: numpy array, the training data, used to calculate steps per epoch.\n    - batch_size: int, the batch size used for training.\n    - epochs: int, the number of epochs to train the model.\n\n    Returns:\n    - history: History, the history object containing training and validation loss and accuracy metrics.\n    \"\"\"\n    adamw_optimizer = get_adamw_optimizer()\n\n    # Compile the model with the AdamW optimizer and accuracy metrics\n    model.compile(loss='categorical_crossentropy', optimizer=adamw_optimizer, metrics=['accuracy'])\n\n    # Combine augmented and non-augmented training datasets\n    train_datasets_combined = tf.data.experimental.sample_from_datasets([train_dataset_augment, train_dataset], weights=[0.5, 0.5])\n\n    # Callbacks for learning rate scheduling and model checkpointing\n    def scheduler(epoch, lr):\n        if epoch < 15:\n            return lr\n        elif 15 <= epoch < 30:\n            return lr * math.exp(-0.1)\n        else:\n            return lr * math.exp(-0.2)\n\n    lr_scheduler = LearningRateScheduler(scheduler)\n    checkpoint = ModelCheckpoint('ensnet_best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n\n    # Train the model\n    history = model.fit(train_datasets_combined, steps_per_epoch=len(x_train_split) // batch_size, epochs=epochs, validation_data=val_dataset, callbacks=[lr_scheduler, checkpoint])\n    return history\n\n\ndef evaluate_model(model, val_dataset):\n    score = model.evaluate(val_dataset)\n    print(\"Model saved.\")\n    full_model.save(\"ensnet.h5\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_custom_model(model_path, custom_objects=None):\n    \"\"\"\n    Load a Keras model with custom objects.\n\n    Parameters:\n    - model_path: str, path to the saved model.\n    - custom_objects: dict, mapping names (str) to custom classes or functions to be considered during load.\n\n    Returns:\n    - Loaded Keras model.\n    \"\"\"\n    return load_model(model_path, custom_objects=custom_objects)\n\ndef predict_with_model(model, x_test):\n    \"\"\"\n    Make predictions with a given model.\n\n    Parameters:\n    - model: Loaded Keras model.\n    - x_test: np.array, test dataset.\n\n    Returns:\n    - predictions: np.array, model predictions.\n    \"\"\"\n    predictions = model.predict(x_test)\n    if isinstance(predictions, list):\n        predictions = np.stack(predictions, axis=0)\n    return predictions\n\ndef majority_vote(predictions):\n    \"\"\"\n    Apply a manual majority vote on model predictions.\n\n    Parameters:\n    - predictions: np.array, model predictions with shape (num_samples, num_subnets, num_classes).\n\n    Returns:\n    - final_predictions: np.array, final class predictions after majority voting.\n    \"\"\"\n    predictions = np.transpose(predictions, (1, 0, 2))\n    votes = np.argmax(predictions, axis=-1)\n    final_predictions = np.array([np.bincount(votes[i]).argmax() for i in range(votes.shape[0])])\n    return final_predictions\n\ndef calculate_accuracy(y_true, y_pred):\n    \"\"\"\n    Calculate the accuracy of predictions.\n\n    Parameters:\n    - y_true: np.array, true labels.\n    - y_pred: np.array, predicted labels.\n\n    Returns:\n    - accuracy: float, accuracy of the predictions.\n    \"\"\"\n    return np.mean(y_true == y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy, AUTO = setup_distribution_strategy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, y_train, x_test, y_test = load_and_preprocess_data()\nbatch_size = 100 * strategy.num_replicas_in_sync  # Adjust based on your hardware capabilities\ntrain_dataset_augmented, train_dataset, val_dataset, test_dataset, batch_size = prepare_datasets(\n    x_train, y_train, x_test, y_test, \n    batch_size=batch_size, \n    augment=True  # Change to False if you don't want augmentation\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    full_model =  build_model(strategy)\n    history = compile_and_train_model(\n        full_model, \n        train_dataset_augmented,  # Assuming you want to train with the augmented dataset\n        train_dataset,  # Non-augmented dataset, used for combined training in your function\n        val_dataset, \n        x_train,  # Used to calculate steps_per_epoch. Ensure this is correct.\n        batch_size, \n        epochs=10  # Adjust epochs as needed\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(full_model,val_dataset)    \nmodel_for_inference = load_model(\"ensnet.h5\", custom_objects={\"DropConnectDense\": DropConnectDense})\npredictions = predict_with_model(model_for_inference, x_test)\nfinal_predictions = majority_vote(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert one-hot encoded y_test_split to class indices for comparison\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Calculate and print accuracy\naccuracy = calculate_accuracy(y_test_indices, final_predictions)\nprint(f\"Test Accuracy after Majority Voting: {accuracy * 100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
